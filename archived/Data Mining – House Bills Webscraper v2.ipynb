{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# houseBills_webscraper.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T10:58:27.683044Z",
     "start_time": "2019-11-14T10:58:27.344270Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re, sqlite3, sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium.webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define Bill class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:04:28.709898Z",
     "start_time": "2019-11-12T09:04:28.697942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Bill:\n",
    "    \n",
    "    def __init__(self, bill_id, num, link, congress, short_title, long_title, date_filed, scope, status, author,\n",
    "                 subject, pri_committee, date_lastUpdate, logs, ra):\n",
    "        self.bill_id = bill_id\n",
    "        self.num = num\n",
    "        self.link = link\n",
    "        self.congress = congress\n",
    "        self.short_title = short_title\n",
    "        self.long_title = long_title\n",
    "        self.date_filed = date_filed\n",
    "        self.scope = scope\n",
    "        self.status = status\n",
    "        self.author = author\n",
    "        self.subject = subject\n",
    "        self.pri_committee = pri_committee\n",
    "        self.date_lastUpdate = date_lastUpdate\n",
    "        self.logs = logs\n",
    "        self.ra = ra\n",
    "        self.entities = (bill_id, num, link, congress, short_title, long_title, date_filed, scope, status, author,\n",
    "                 subject, pri_committee, date_lastUpdate, logs, ra)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Congress: ' + str(self.congress) + ' ' + self.num + ': ' + self.short_title\n",
    "    \n",
    "    def insert_bill():\n",
    "        pass\n",
    "    \n",
    "    def update_bill():\n",
    "        pass\n",
    "    \n",
    "    def remove_bill():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compile Regex Patterns\n",
    "These regex patterns will be used to extract relevant strings only from the webscraping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:04:28.735773Z",
     "start_time": "2019-11-12T09:04:28.725988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bill_number_regex = re.compile(r'(?<=\\d\\d&q=).*')\n",
    "filed_date_regex = re.compile(r'(?<=Filed on ).*(?= by )')\n",
    "author_regex = re.compile(r'(?<= by ).*(?=\\n)')\n",
    "status_regex = re.compile(r'.*(?= \\()')\n",
    "last_update_regex = re.compile(r'(?<=\\().*(?=\\))')\n",
    "logs_regex = re.compile(r'(?<=\\n\\[ \\d\\d\\d\\d \\]\\n).*(?=\\(The (legislative history)|(LEGISLATIVE HISTORY))',re.DOTALL)\n",
    "logs_wFootNote_regex = re.compile(r'(?<=\\[ \\d\\d\\d\\d ]\\n).*',re.DOTALL)\n",
    "ra_regex = re.compile(r'(?<=\\nRepublic Act No\\. )\\d*(?=(\\n)| )',re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Scraper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getBill function is our main web scraping script. It follows the following workflow: <br>\n",
    "1. Access Home URL of 'senate.gov.ph' <br>\n",
    "2. Collect all the bills' links on that page.<br>\n",
    "3. Iterate over the gathered links.<br>\n",
    "4. Click the \"All Information\" button and then scrape all the bills' informations from that frame.<br>\n",
    "5. Go to next page from the Home URL and repeat all steps again.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### bills_logScraper\n",
    "Scraper for special case of logs wherein the footnote is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:04:28.747420Z",
     "start_time": "2019-11-12T09:04:28.741343Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bills_logScraper(logs):\n",
    "    try:\n",
    "        return logs_regex.search(logs).group()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            return logs_wFootNote_regex.search(logs).group()\n",
    "        except AttributeError:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getBill function\n",
    "Our main scraping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:11:27.052445Z",
     "start_time": "2019-11-12T09:11:27.031104Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getBill(congress_num, page_num):\n",
    "    \n",
    "    driver = selenium.webdriver.PhantomJS()\n",
    "    \n",
    "    home_url = 'http://www.congress.gov.ph/legisdocs/?v=bills'\n",
    "    res = requests.get(home_url)\n",
    "    res.raise_for_status()\n",
    "    print('Accessing '+ 'http://www.congress.gov.ph' + ' ...\\n')\n",
    "    \n",
    "    # Select th congress from dropdown.\n",
    "    select = Select(driver.find_element_by_xpath(\"//select[@name='congress']\"))\n",
    "    select.select_by_value(congress_num)\n",
    "    go_btn = driver.find_element_by_xpath(\"//form[@class='form-inline pull-right']//input[@class='btn btn-default input-sm']\")\n",
    "    go_btn.click()\n",
    "    element = WebDriverWait(driver,10).until(lambda x:x.find_element_by_xpath(\"//p[contains(text(),'Legislative History')]\")) \n",
    "    related_links_element = WebDriverWait(driver, 10).until(lambda x:x.find_element_by_xpath=(\"\"))\n",
    "    \n",
    "    res = requests.get(home_url)\n",
    "    res.raise_for_status()\n",
    "    print('Selecting House Bills...')\n",
    "    \n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    sublinks=[str(bill.attrs['href']) for bill in soup.select('a') if 'bill_res' in str(bill.attrs['href'])]\n",
    "    print('There are ' + str(len(sublinks)) + ' bills on this page, '+ 'p' + str(page_num) + '.\\n')\n",
    "    \n",
    "    bills_dict = OrderedDict()\n",
    "    fetch_errors = []\n",
    "    for sublink in sublinks:\n",
    "        #\n",
    "        link = 'http://www.senate.gov.ph/lis/'+sublink\n",
    "        num = bill_number_regex.search(sublink).group()\n",
    "        print(\"Trying to access child link \"+ link + ' ...')\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(100)\n",
    "        try:\n",
    "            allInfo_btn = driver.find_element_by_xpath(\"//a[@id='lbAll']\")\n",
    "        except NoSuchElementException:\n",
    "            print('\\t' + str(num) + ' is missing! Skipping...\\n')\n",
    "            fetch_errors.append(num)\n",
    "            continue\n",
    "        \n",
    "        allInfo_btn.click()\n",
    "        element = WebDriverWait(driver,10).until(lambda x:x.find_element_by_xpath(\"//p[contains(text(),'Legislative History')]\")) \n",
    "        soup_allinfo = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        short_title = soup_allinfo.select('p[class=\"h1_bold\"]')[0].getText()\n",
    "        allinfo_frame_text = soup_allinfo.select('td[id=\"content\"]')[0].getText()\n",
    "        date_filed = filed_date_regex.search(allinfo_frame_text).group()\n",
    "        author = author_regex.search(allinfo_frame_text).group()\n",
    "        long_title = soup_allinfo.select('blockquote')[0].getText()\n",
    "        scope = soup_allinfo.select('blockquote')[1].getText()\n",
    "        \n",
    "        legis_status = soup_allinfo.select('blockquote')[2].getText()\n",
    "        blkqt_idx = 3 if 'HBN-' in legis_status else 2 # place holder for bills w/ \"House counterpart bill no.\"\n",
    "            \n",
    "        legis_status = soup_allinfo.select('blockquote')[blkqt_idx].getText()\n",
    "        status = status_regex.search(legis_status).group()\n",
    "        date_lastUpdate = last_update_regex.search(legis_status).group()\n",
    "        \n",
    "        # Special case if a bill was 'Withdrawn.'\n",
    "        if 'Withdrawn' in status:\n",
    "            subject, pri_committee, logs, ra = ('','','','')\n",
    "        else: \n",
    "            subject = soup_allinfo.select('blockquote')[blkqt_idx + 1].getText()       \n",
    "            pri_committee = soup_allinfo.select('blockquote')[blkqt_idx + 2].getText()\n",
    "        \n",
    "            all_blkquotes = '\\n'.join([soup_allinfo.select('blockquote')[i].\n",
    "                               getText() for i in range(len(soup_allinfo.select('blockquote')))])        \n",
    "            logs = bills_logScraper(all_blkquotes)\n",
    "\n",
    "            try:\n",
    "                ra = ra_regex.search(all_blkquotes).group()\n",
    "            except AttributeError:\n",
    "                ra = ''\n",
    "        \n",
    "        # Create unique id for this record.\n",
    "        bill_id = str(congress_num) + str(num)\n",
    "        bills_dict[bill_id]=(bill_id, num, link, congress_num, short_title, long_title, date_filed, scope, status, author,\n",
    "                 subject, pri_committee, date_lastUpdate, logs, ra)\n",
    "        print('\\t' + str(num) + ' has been successfully scraped.\\n')\n",
    "        \n",
    "    print('All Bills have been successfully scraped on this page.')\n",
    "    # Must close the ghostDriver before exiting this function...\n",
    "    driver.quit()\n",
    "    \n",
    "    return bills_dict, fetch_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define getMax_page function\n",
    "This function will get the maximum/last page number of a Congressional Bill list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:22:45.560829Z",
     "start_time": "2019-11-12T09:22:45.556289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getMax_page(congress_num):\n",
    "    driver = selenium.webdriver.PhantomJS()\n",
    "    home_url = 'http://www.senate.gov.ph/lis/leg_sys.aspx?congress='+str(congress_num)+'&type=bill&p=999'\n",
    "    driver.get(home_url)\n",
    "    driver.implicitly_wait(100)\n",
    "    \n",
    "    select = Select(driver.find_element_by_xpath(\"//select[@id='dlBillType']\"))\n",
    "    select.select_by_value('HBN')\n",
    "\n",
    "    print('Selecting House Bills...')\n",
    "\n",
    "    soup_pagination = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    maxPage = int(soup_pagination.select('div[class=\"lis_pagenav\"] a')[-1].getText()) + 1\n",
    "    \n",
    "    driver.quit()\n",
    "    return maxPage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define Database functions\n",
    "These database functions will create a database connection instance. It will create table within the database, check for records, insert records, as well as update existing records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:04:28.799684Z",
     "start_time": "2019-11-12T09:04:28.788010Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def connect_db(database):\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        cursor = conn.cursor()\n",
    "        return conn, cursor\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Error in connecting to sqlite3\", error)\n",
    "\n",
    "def create_bills_table(conn, cursor):\n",
    "    cursor.execute(\"\"\"CREATE TABLE if not exists houseBills(\n",
    "                    bill_id text PRIMARY KEY,\n",
    "                    num text,\n",
    "                    link text,\n",
    "                    congress integer,\n",
    "                    short_title text,\n",
    "                    long_title text,\n",
    "                    date_filed text,\n",
    "                    scope text,\n",
    "                    status integer,\n",
    "                    author text,\n",
    "                    subject text,\n",
    "                    pri_committee text,\n",
    "                    date_lastUpdate text,\n",
    "                    logs text,\n",
    "                    ra text)\"\"\")\n",
    "    conn.commit()\n",
    "    \n",
    "def check_bill_exists(bill_id, conn, cursor):\n",
    "    with conn:\n",
    "        cursor.execute(\"SELECT bill_id FROM houseBills WHERE bill_id = (?)\",(bill_id,))\n",
    "    rows = cursor.fetchall()\n",
    "    return True if len(rows) else False\n",
    "\n",
    "def insert_bill(entities, conn, cursor):\n",
    "    with conn:\n",
    "        cursor.execute(\"\"\"INSERT INTO houseBills(\n",
    "                        bill_id, num, link, congress, short_title, long_title, date_filed, \n",
    "                        scope, status, author, subject, pri_committee, \n",
    "                        date_lastUpdate, logs, ra) VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\"\"\",(entities))\n",
    "        conn.commit()\n",
    "        \n",
    "def update_date_lastUpdate(bill_id, date_lastUpdate, conn, cursor):\n",
    "    with conn:\n",
    "        cursor.execute(\"UPDATE houseBills SET date_lastUpdate = (?) WHERE bill_id = (?)\",(date_lastUpdate, bill_id))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define scrape_thisCongress function\n",
    "This function accepts nth Congress as an argument, _and where n is an integer,_ and scrapes through all the bills in all the available pages under that Congress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:04:28.812515Z",
     "start_time": "2019-11-12T09:04:28.803911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scrape_thisCongress(congress, start_page):\n",
    "    pages = list(range(start_page, getMax_page(congress) + 1, 1))\n",
    "    conn, cursor = connect_db('phBills.db')\n",
    "    create_bills_table(conn, cursor)\n",
    "    bill_count = 0\n",
    "    scraping_failures = []\n",
    "    for page in pages:\n",
    "        thisPage_bills, scrape_failures = getBill(congress, page)\n",
    "        scraping_failures.extend(scrape_failures)\n",
    "        for bill, contents in thisPage_bills.items():\n",
    "            some_bill = Bill(*contents)\n",
    "            if check_bill_exists(some_bill.bill_id, conn, cursor):\n",
    "                print(str(some_bill) + \" already exists in our database. Updating 'date_lastUpdate' field instead.\")\n",
    "                update_date_lastUpdate(some_bill.bill_id, some_bill.date_lastUpdate, conn, cursor)\n",
    "            else:\n",
    "                insert_bill(some_bill.entities, conn, cursor)\n",
    "            bill_count += 1\n",
    "    print('\\nCollected ' + str(bill_count) + ' bills from ' + str(congress) + 'th congress.')\n",
    "    print('Disconnecting from http://www.senate.gov.ph...')\n",
    "    conn.close()\n",
    "    print('Done!')\n",
    "    return bill_count, scraping_failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T11:00:05.828736Z",
     "start_time": "2019-11-14T10:58:36.259753Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing http://www.congress.gov.ph ...\n",
      "\n",
      "17th Congress selected.\n",
      "go button clicked!\n",
      "History view shown...\n",
      "Soup is delivered.\n"
     ]
    }
   ],
   "source": [
    "congress_num = 17\n",
    "driver = selenium.webdriver.PhantomJS()\n",
    "home_url = 'http://www.congress.gov.ph/legisdocs/?v=bills'\n",
    "\n",
    "print('Accessing '+ 'http://www.congress.gov.ph' + ' ...\\n')\n",
    "\n",
    "driver.get(home_url)\n",
    "driver.implicitly_wait(100)\n",
    "\n",
    "WebDriverWait(driver,10).until(lambda x:x.find_element_by_xpath(\"//li[contains(text(),'RELATED LINKS')]\"))\n",
    "# rl_element = WebDriverWait(driver,10).until(lambda x:x.find_element_by_xpath(\"//a[contains(text(),'ABOUT US')]\")) \n",
    "\n",
    "# Select th congress from dropdown.\n",
    "dropdown = Select(driver.find_element_by_name('congress'))\n",
    "dropdown.select_by_value(str(congress_num))\n",
    "print(f\"{congress_num}th Congress selected.\")\n",
    "\n",
    "go_btn = driver.find_element_by_xpath(\"//form[@class='form-inline pull-right']//input[@class='btn btn-default input-sm']\")\n",
    "go_btn.click()\n",
    "print(\"go button clicked!\")\n",
    "\n",
    "WebDriverWait(driver,10).until(lambda x:x.find_element_by_xpath(\"//li[contains(text(),'RELATED LINKS')]\"))\n",
    "\n",
    "history_btn = driver.find_element_by_xpath(\"/html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[3]/span[1]/a[1]\")\n",
    "history_btn.click()\n",
    "WebDriverWait(driver,10).until(lambda x:x.find_element_by_xpath(\"//div[@class='modal-header']\"))\n",
    "print(\"History view shown...\")\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(\"Soup is delivered.\")\n",
    "    \n",
    "    \n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[3]/span[1]/a[1]\n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[5]/span[1]/a[1]\n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[7]/span[1]/a[1]\n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[9]/span[1]/a[1]\n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[11]/span[1]/a[1]\n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[10133]/span[1]/a[1]\n",
    "# /html[1]/body[1]/div[2]/div[1]/div[1]/div[2]/div[10135]/span[1]/a[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T09:24:24.034127Z",
     "start_time": "2019-11-14T09:24:23.864729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div[class='modal-body'] div[class='fetched-data'] tbody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T09:30:15.611323Z",
     "start_time": "2019-11-14T09:30:14.379281Z"
    }
   },
   "outputs": [],
   "source": [
    "soup.find('tbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T09:30:54.012933Z",
     "start_time": "2019-11-14T09:30:52.777678Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a36e3824e2cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtable_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tbody'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "table_body = soup.find('tbody')\n",
    "rows = table_body.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T09:31:17.087458Z",
     "start_time": "2019-11-14T09:31:17.081978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "989px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

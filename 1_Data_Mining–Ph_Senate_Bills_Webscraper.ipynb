{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senate Bills Webscraper\n",
    "This program can collect Philippine bills filed by the senate from the 13th Congress to the the current 18th Congress from this Government website: https://www.senate.gov.ph/lis/leg_sys.aspx\n",
    "<br>\n",
    "The collected data is then saved to a sql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.512760Z",
     "start_time": "2019-11-12T04:42:02.060265Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "from collections import OrderedDict\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Install and setup chromedriver first if this is the first time using it. You can download it here: https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "<br>\n",
    "Also, make sure chromedriver is compatible with installed Google Chrome App.<br>\n",
    "Go to Help -> About Google Chrome -> Chrome will automatically look for updates _(update Chrome to the latest version)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a chrome options object.\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a web driver object.\n",
    "driver_path = '/Users/emilolbinado/opt/miniconda3/bin/chromedriver'\n",
    "driver = webdriver.Chrome(options=chrome_options, executable_path=driver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Bill class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.524009Z",
     "start_time": "2019-11-12T04:42:02.516161Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bill:\n",
    "    '''This class help define an object to be a bill with specified\n",
    "    bill attributes.'''\n",
    "\n",
    "    def __init__(self, bill_id, num, link, congress, short_title, long_title,\n",
    "                 date_filed, scope, status, author, subject, pri_committee,\n",
    "                 date_lastUpdate, logs, ra):\n",
    "        self.bill_id = bill_id\n",
    "        self.num = num\n",
    "        self.link = link\n",
    "        self.congress = congress\n",
    "        self.short_title = short_title\n",
    "        self.long_title = long_title\n",
    "        self.date_filed = date_filed\n",
    "        self.scope = scope\n",
    "        self.status = status\n",
    "        self.author = author\n",
    "        self.subject = subject\n",
    "        self.pri_committee = pri_committee\n",
    "        self.date_lastUpdate = date_lastUpdate\n",
    "        self.logs = logs\n",
    "        self.ra = ra\n",
    "        self.entities = (bill_id, num, link, congress, short_title, long_title,\n",
    "                         date_filed, scope, status, author, subject,\n",
    "                         pri_committee, date_lastUpdate, logs, ra)\n",
    "\n",
    "    def __str__(self):\n",
    "        '''This function will show details of the class Bill\n",
    "        if an instance of Bill is passed on a print statement.'''\n",
    "        return ('Congress: ' + str(self.congress) + ' ' + self.num + ': '\n",
    "                + self.short_title)\n",
    "\n",
    "    def insert_bill():\n",
    "        pass\n",
    "\n",
    "    def update_bill():\n",
    "        pass\n",
    "\n",
    "    def remove_bill():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Regex Patterns\n",
    "These regex patterns will be used to extract relevant strings only from the webscraping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.534196Z",
     "start_time": "2019-11-12T04:42:02.526173Z"
    }
   },
   "outputs": [],
   "source": [
    "bill_number_regex = re.compile(r'(?<=\\d\\d&q=).*')\n",
    "filed_date_regex = re.compile(r'(?<=Filed on ).*(?= by )')\n",
    "author_regex = re.compile(r'(?<= by ).*(?=\\n)')\n",
    "status_regex = re.compile(r'.*(?= \\()')\n",
    "last_update_regex = re.compile(r'(?<=\\().*(?=\\))')\n",
    "logs_regex = re.compile(r'(?<=\\n\\[ \\d\\d\\d\\d \\]\\n).*(?=\\(The (legislative history)|(LEGISLATIVE HISTORY))', re.DOTALL)\n",
    "logs_wFootNote_regex = re.compile(r'(?<=\\[ \\d\\d\\d\\d ]\\n).*', re.DOTALL)\n",
    "ra_regex = re.compile(r'(?<=\\nRepublic Act No\\. )\\d*(?=(\\n)| )', re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Web Scraper functions\n",
    "getBill function is our main web scraping script. It follows the following workflow: <br>\n",
    "1. Access Home URL of 'senate.gov.ph' <br>\n",
    "2. Collect all the bills' links on that page.<br>\n",
    "3. Iterate over the gathered links.<br>\n",
    "4. Click the \"All Information\" button and then scrape all the bills' informations from that frame.<br>\n",
    "5. Go to next page from the Home URL and repeat all steps again.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.569909Z",
     "start_time": "2019-11-12T04:42:02.548846Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getBill(driver, congress_num, page_num):\n",
    "    '''The getBill function accepts two arguments; 1. congress_num(type: int)\n",
    "    to specify nth congress and 2. page_num(type: int) to specify the page\n",
    "    number. Both will help Selenium navigate specific page to scrape.'''\n",
    "    home_url = ('http://www.senate.gov.ph/lis/leg_sys.aspx?congress=' +\n",
    "                str(congress_num)+'&type=bill&p='+str(page_num))\n",
    "    res = requests.get(home_url)\n",
    "    res.raise_for_status()\n",
    "    print('Accessing ' +\n",
    "          'http://www.senate.gov.ph' + ' ...\\n')\n",
    "\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    sublinks = [str(bill.attrs['href']) for bill in soup.select('a')\n",
    "                if 'bill_res' in str(bill.attrs['href'])]\n",
    "    print('There are ' + str(len(sublinks)) + ' bills on this page, ' +\n",
    "          'p' + str(page_num) + '.\\n')\n",
    "\n",
    "    bills_dict = OrderedDict()\n",
    "    fetch_errors = []\n",
    "    for sublink in sublinks:\n",
    "        link = 'http://www.senate.gov.ph/lis/'+sublink\n",
    "        num = bill_number_regex.search(sublink).group()\n",
    "        print(\"Trying to access child link \" + link + ' ...')\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(100)\n",
    "        try:\n",
    "            allInfo_btn = driver.find_element_by_xpath(\"//a[@id='lbAll']\")\n",
    "        except NoSuchElementException:\n",
    "            print('\\t' + str(num) + ' is missing! Skipping...\\n')\n",
    "            fetch_errors.append(num)\n",
    "            continue\n",
    "\n",
    "        allInfo_btn.click()\n",
    "        element = WebDriverWait(driver,\n",
    "                                10).until(lambda x:\n",
    "                                          x.find_element_by_xpath(\"//p[contains(text(), 'Legislative History')]\"))\n",
    "        soup_allinfo = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        short_title = soup_allinfo.select('p[class=\"h1_bold\"]')[0].getText()\n",
    "        allinfo_frame_text = soup_allinfo.select('td[id=\"content\"]')[0].getText()\n",
    "        date_filed = filed_date_regex.search(allinfo_frame_text).group()\n",
    "        author = author_regex.search(allinfo_frame_text).group()\n",
    "        long_title = soup_allinfo.select('blockquote')[0].getText()\n",
    "        scope = soup_allinfo.select('blockquote')[1].getText()\n",
    "        legis_status = soup_allinfo.select('blockquote')[2].getText()\n",
    "        # Place holder for bills w/ \"House counterpart bill no.\"\n",
    "        blkqt_idx = 3 if 'HBN-' in legis_status else 2\n",
    "        legis_status = soup_allinfo.select('blockquote')[blkqt_idx].getText()\n",
    "        status = status_regex.search(legis_status).group()\n",
    "        date_lastUpdate = last_update_regex.search(legis_status).group()\n",
    "        # Special case if a bill was 'Withdrawn.'\n",
    "        if 'Withdrawn' in status:\n",
    "            subject, pri_committee, logs, ra = ('', '', '', '')\n",
    "        else:\n",
    "            subject = soup_allinfo.select('blockquote')[blkqt_idx + 1].getText()\n",
    "            pri_committee = (soup_allinfo.select('blockquote')\n",
    "                             [blkqt_idx + 2].getText())\n",
    "\n",
    "            all_blkquotes = '\\n'.join([soup_allinfo.select('blockquote')[i].\n",
    "                                       getText()\n",
    "                                       for i in range(len(soup_allinfo.select('blockquote')))])\n",
    "            logs = bills_logScraper(all_blkquotes)\n",
    "\n",
    "            try:\n",
    "                ra = ra_regex.search(all_blkquotes).group()\n",
    "            except AttributeError:\n",
    "                ra = ''\n",
    "        # Create unique id for this record.\n",
    "        bill_id = str(congress_num) + str(num)\n",
    "        bills_dict[bill_id] = (bill_id, num, link, congress_num, short_title,\n",
    "                               long_title, date_filed, scope, status, author,\n",
    "                               subject, pri_committee, date_lastUpdate, logs,\n",
    "                               ra)\n",
    "        print('\\t' + str(num) + ' has been successfully scraped.\\n')\n",
    "    print('All Bills have been successfully scraped on this page.')\n",
    "    return bills_dict, fetch_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.545314Z",
     "start_time": "2019-11-12T04:42:02.536813Z"
    }
   },
   "outputs": [],
   "source": [
    "def bills_logScraper(logs):\n",
    "    '''Scraper for special cases of bill's logs wherein\n",
    "    the footnote maybe missing.'''\n",
    "    try:\n",
    "        return logs_regex.search(logs).group()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            return logs_wFootNote_regex.search(logs).group()\n",
    "        except AttributeError:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.577877Z",
     "start_time": "2019-11-12T04:42:02.572304Z"
    }
   },
   "outputs": [],
   "source": [
    "def getMax_page(driver, congress_num):\n",
    "    '''This function will get the maximum/last page number of a\n",
    "    Congressional Bill list.'''\n",
    "    home_url = ('http://www.senate.gov.ph/lis/leg_sys.aspx?congress=' +\n",
    "                str(congress_num)+'&type=bill&p=999')\n",
    "    driver.get(home_url)\n",
    "    driver.implicitly_wait(100)\n",
    "    soup_pagination = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    maxPage = (int(soup_pagination.\n",
    "                   select('div[class=\"lis_pagenav\"] a')[-1].getText()) + 1)\n",
    "    return maxPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.600224Z",
     "start_time": "2019-11-12T04:42:02.592550Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_thisCongress(congress, start_page):\n",
    "    '''This function accepts nth Congress as an argument, (type: int),\n",
    "    scrapes through all the bills in all the available pages,\n",
    "    starting from 'start_page', (type: int), under that Congress.'''\n",
    "    driver = webdriver.Chrome(options=chrome_options,\n",
    "                              executable_path=driver_path)\n",
    "    pages = list(range(start_page, getMax_page(driver, congress) + 1, 1))\n",
    "    conn, cursor = connect_db('phBills.db')\n",
    "    create_bills_table(conn, cursor)\n",
    "    bill_count = 0\n",
    "    scraping_failures = []\n",
    "    for page in pages:\n",
    "        thisPage_bills, scrape_failures = getBill(driver, congress, page)\n",
    "        scraping_failures.extend(scrape_failures)\n",
    "        for bill, contents in thisPage_bills.items():\n",
    "            some_bill = Bill(*contents)\n",
    "            if check_bill_exists(some_bill.bill_id, conn, cursor):\n",
    "                print(str(some_bill) + ''' already exists in our database.\n",
    "                Updating 'date_lastUpdate' field instead.''')\n",
    "                update_date_lastUpdate(some_bill.bill_id,\n",
    "                                       some_bill.date_lastUpdate, conn, cursor)\n",
    "            else:\n",
    "                insert_bill(some_bill.entities, conn, cursor)\n",
    "            bill_count += 1\n",
    "    print('\\nCollected ' + str(bill_count) + ' bills from ' +\n",
    "          str(congress) + 'th congress.')\n",
    "    print('Disconnecting from http://www.senate.gov.ph...')\n",
    "    driver.quit()\n",
    "    conn.close()\n",
    "    print('Done!')\n",
    "    return bill_count, scraping_failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Database functions\n",
    "Functions will create a database connection instance. It will create table within the database, check for records, insert records, as well as update existing records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T04:42:02.590333Z",
     "start_time": "2019-11-12T04:42:02.580243Z"
    }
   },
   "outputs": [],
   "source": [
    "def connect_db(database):\n",
    "    '''Establish a connection to the database.'''\n",
    "    try:\n",
    "        conn = sqlite3.connect(database)\n",
    "        cursor = conn.cursor()\n",
    "        return conn, cursor\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Error in connecting to sqlite3\", error)\n",
    "\n",
    "\n",
    "def create_bills_table(conn, cursor):\n",
    "    '''If not existing, create a database table to house the senate bills data.\n",
    "    '''\n",
    "    cursor.execute(\"\"\"CREATE TABLE if not exists senateBills(\n",
    "                    bill_id text PRIMARY KEY,\n",
    "                    num text,\n",
    "                    link text,\n",
    "                    congress integer,\n",
    "                    short_title text,\n",
    "                    long_title text,\n",
    "                    date_filed text,\n",
    "                    scope text,\n",
    "                    status integer,\n",
    "                    author text,\n",
    "                    subject text,\n",
    "                    pri_committee text,\n",
    "                    date_lastUpdate text,\n",
    "                    logs text,\n",
    "                    ra text)\"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def check_bill_exists(bill_id, conn, cursor):\n",
    "    '''Check if certain scraped bill already exist on the database.'''\n",
    "    with conn:\n",
    "        cursor.execute(\"SELECT bill_id FROM senateBills WHERE bill_id = (?)\",\n",
    "                       (bill_id,))\n",
    "    rows = cursor.fetchall()\n",
    "    return True if len(rows) else False\n",
    "\n",
    "\n",
    "def insert_bill(entities, conn, cursor):\n",
    "    '''Insert the scraped bill to the database.'''\n",
    "    with conn:\n",
    "        cursor.execute(\"\"\"INSERT INTO senateBills(\n",
    "                        bill_id, num, link, congress, short_title, long_title,\n",
    "                        date_filed, scope, status, author, subject,\n",
    "                        pri_committee, date_lastUpdate, logs, ra)\n",
    "                        VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\"\"\", (entities))\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def update_date_lastUpdate(bill_id, date_lastUpdate, conn, cursor):\n",
    "    '''If bill is already existing to database, update the record instead. '''\n",
    "    with conn:\n",
    "        cursor.execute('''UPDATE senateBills\n",
    "        SET date_lastUpdate = (?) WHERE bill_id = (?)''', (date_lastUpdate,\n",
    "                                                           bill_id))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing http://www.senate.gov.ph ...\n",
      "\n",
      "There are 8 bills on this page, p335.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-10 ...\n",
      "\tSBN-10 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-9 ...\n",
      "\tSBN-9 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-8 ...\n",
      "\tSBN-8 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-7 ...\n",
      "\tSBN-7 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-6 ...\n",
      "\tSBN-6 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-5 ...\n",
      "\tSBN-5 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-4 ...\n",
      "\tSBN-4 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-3 ...\n",
      "\tSBN-3 has been successfully scraped.\n",
      "\n",
      "All Bills have been successfully scraped on this page.\n",
      "Accessing http://www.senate.gov.ph ...\n",
      "\n",
      "There are 2 bills on this page, p336.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-2 ...\n",
      "\tSBN-2 has been successfully scraped.\n",
      "\n",
      "Trying to access child link http://www.senate.gov.ph/lis/bill_res.aspx?congress=13&q=SBN-1 ...\n",
      "\tSBN-1 has been successfully scraped.\n",
      "\n",
      "All Bills have been successfully scraped on this page.\n",
      "\n",
      "Collected 10 bills from 13th congress.\n",
      "Disconnecting from http://www.senate.gov.ph...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape bills from 335th page to last page of the 13th Congress Senate Bills.\n",
    "scrape_thisCongress(13, 335)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
